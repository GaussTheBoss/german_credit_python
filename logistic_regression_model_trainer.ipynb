{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Notebook to Deployable Model:\n",
    "## Training, Evaluating, and Conforming a Model for Deployment\n",
    "\n",
    "\n",
    "In this notebook, we demonstrate the process of \n",
    "1. training a model, \n",
    "2. evaluating its performance, \n",
    "3. saving it for later use,\n",
    "4. and conforming it to deployment standards.\n",
    "\n",
    "More specifically, we will train a logistic regression classifier on the German Credit Data dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I - Model Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by loading relevant libraries. We will need `sklearn` for model training, and `aequitas` for bias detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from typing import List\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "\n",
    "from aequitas.bias import Bias\n",
    "from aequitas.group import Group\n",
    "from aequitas.preprocessing import preprocess_input_df\n",
    "\n",
    "from sklearn import set_config\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    "    RepeatedStratifiedKFold,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    make_scorer,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    fbeta_score,\n",
    "    balanced_accuracy_score,\n",
    "    confusion_matrix,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **German Credit Data** dataset can be found here: https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data). Download it and load it from a *CSV* file. \n",
    "\n",
    " - For our purposes, the dataset has been modified slightly to include an `id` column, and a `gender` column (engineered from `status_sex`, used to demonstarte bias). \n",
    " \n",
    "  - The target variable is under `label`. We have mapped the labels `[1,2]` to `[0,1]`, where `1` indicates the positive class (loan default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv(\"german_credit_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'duration_months', 'credit_amount', 'installment_rate',\n",
       "       'present_residence_since', 'age_years', 'number_existing_credits',\n",
       "       'checking_status', 'credit_history', 'purpose', 'savings_account',\n",
       "       'present_employment_since', 'debtors_guarantors', 'property',\n",
       "       'installment_plans', 'housing', 'job', 'number_people_liable',\n",
       "       'telephone', 'foreign_worker', 'gender', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>duration_months</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>installment_rate</th>\n",
       "      <th>present_residence_since</th>\n",
       "      <th>age_years</th>\n",
       "      <th>number_existing_credits</th>\n",
       "      <th>checking_status</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>...</th>\n",
       "      <th>debtors_guarantors</th>\n",
       "      <th>property</th>\n",
       "      <th>installment_plans</th>\n",
       "      <th>housing</th>\n",
       "      <th>job</th>\n",
       "      <th>number_people_liable</th>\n",
       "      <th>telephone</th>\n",
       "      <th>foreign_worker</th>\n",
       "      <th>gender</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1169</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>A11</td>\n",
       "      <td>A34</td>\n",
       "      <td>A43</td>\n",
       "      <td>...</td>\n",
       "      <td>A101</td>\n",
       "      <td>A121</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A192</td>\n",
       "      <td>A201</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>5951</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>A12</td>\n",
       "      <td>A32</td>\n",
       "      <td>A43</td>\n",
       "      <td>...</td>\n",
       "      <td>A101</td>\n",
       "      <td>A121</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2096</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>A14</td>\n",
       "      <td>A34</td>\n",
       "      <td>A46</td>\n",
       "      <td>...</td>\n",
       "      <td>A101</td>\n",
       "      <td>A121</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>A172</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>7882</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>A11</td>\n",
       "      <td>A32</td>\n",
       "      <td>A42</td>\n",
       "      <td>...</td>\n",
       "      <td>A103</td>\n",
       "      <td>A122</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>4870</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>A11</td>\n",
       "      <td>A33</td>\n",
       "      <td>A40</td>\n",
       "      <td>...</td>\n",
       "      <td>A101</td>\n",
       "      <td>A124</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  duration_months  credit_amount  installment_rate  \\\n",
       "0   0                6           1169                 4   \n",
       "1   1               48           5951                 2   \n",
       "2   2               12           2096                 2   \n",
       "3   3               42           7882                 2   \n",
       "4   4               24           4870                 3   \n",
       "\n",
       "   present_residence_since  age_years  number_existing_credits  \\\n",
       "0                        4         67                        2   \n",
       "1                        2         22                        1   \n",
       "2                        3         49                        1   \n",
       "3                        4         45                        1   \n",
       "4                        4         53                        2   \n",
       "\n",
       "  checking_status credit_history purpose  ... debtors_guarantors property  \\\n",
       "0             A11            A34     A43  ...               A101     A121   \n",
       "1             A12            A32     A43  ...               A101     A121   \n",
       "2             A14            A34     A46  ...               A101     A121   \n",
       "3             A11            A32     A42  ...               A103     A122   \n",
       "4             A11            A33     A40  ...               A101     A124   \n",
       "\n",
       "  installment_plans housing   job number_people_liable telephone  \\\n",
       "0              A143    A152  A173                    1      A192   \n",
       "1              A143    A152  A173                    1      A191   \n",
       "2              A143    A152  A172                    2      A191   \n",
       "3              A143    A153  A173                    2      A191   \n",
       "4              A143    A153  A173                    2      A191   \n",
       "\n",
       "   foreign_worker  gender label  \n",
       "0            A201    male     0  \n",
       "1            A201  female     1  \n",
       "2            A201    male     0  \n",
       "3            A201    male     0  \n",
       "4            A201    male     1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all numeric columns need to be considered as numerical features. For example, `number_people_liable` only has two unique **discrete** values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    845\n",
       "2    155\n",
       "Name: number_people_liable, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.number_people_liable.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may therefore treat it as a categorical feature. Note, however, that we may need to reconsider this option if more values appear in testing phases. In a production environment, care must be taken to deal with extraneous (unobserved) values.\n",
    "\n",
    "Per `pandas` documentation, there are memory imrovements if `object` fields are cast as `category` type, especially when the number of values for such fields is small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.number_people_liable = data.number_people_liable.astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding any further with model development, let us split the original dataset into two sets: \n",
    "\n",
    " - a **baseline/training** set that will be used as a reference set, and \n",
    " \n",
    "  - a **sample** set which will mimic input data to the model once the model is in use (PROD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a random state for reproducability\n",
    "df_baseline, df_sample = train_test_split(data, train_size=0.8, random_state=0)\n",
    "\n",
    "# Writing split datasets into JSON-lines (tabular) files\n",
    "df_baseline.to_json(\"df_baseline.json\", orient=\"records\", lines=True)\n",
    "df_sample.to_json(\"df_sample.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the primary distributions to looks at is that of the label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.6975\n",
       "1    0.3025\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_baseline.label.value_counts() / len(df_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.71\n",
       "1    0.29\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.label.value_counts() / len(df_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that in either set, around 70% of the accounts have Paid Off the loan `(label=0)`, while the remaining 30% have defaulted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train a **Logistic Regression** classifier. Since our data contains categorical features, we will need to start our pipeline with an encoder. The pipeline below will One-Hot-Encode input data, then fit a LogisticRegression against the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    OneHotEncoder(handle_unknown=\"ignore\", sparse=True),\n",
    "    LogisticRegression(max_iter=1000, random_state=0),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression** has multiple parameters which can be tuned. Among these are `C`, `solver`, and `class_weight`. Instead of manually seraching for the optimal set of parameters, we will use **GridSearchCV**. We provide GridSearchCV a list of values for each of these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict(\n",
    "    logisticregression__C=numpy.logspace(\n",
    "        -4, 4, 50\n",
    "    ),  # Inverse of regularization strength\n",
    "    logisticregression__solver=[\"liblinear\", \"lbfgs\", \"newton-cg\"],\n",
    "    logisticregression__class_weight=[\"balanced\", None],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data still contains non-predictive features, such as `id`, `label`, `age_years` and `gender`. We remove these below. \n",
    "\n",
    "**Note** - `gender` and `age_years` are removed to avoid explicit bias. This does not gaurantee, however, that the overall model will not be biased against a particular group,  since bias could be implicitely encoded in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive_features = list(\n",
    "    set(data.columns) - set([\"id\", \"label\", \"age_years\", \"gender\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, let us see which features are automatically encoded as **numerical**, and which are encoded as **categorical**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = list(\n",
    "    set(predictive_features).intersection(\n",
    "        set(data.select_dtypes(include=[\"object\", \"category\"]))\n",
    "    )\n",
    ")\n",
    "numerical_features = list(\n",
    "    set(predictive_features).intersection(set(data.select_dtypes(include=[\"number\"])))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Categorical features**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['installment_plans', 'job', 'purpose', 'telephone', 'number_people_liable', 'present_employment_since', 'savings_account', 'debtors_guarantors', 'housing', 'checking_status', 'credit_history', 'foreign_worker', 'property']\n"
     ]
    }
   ],
   "source": [
    "print(categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numerical features**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['number_existing_credits', 'present_residence_since', 'credit_amount', 'installment_rate', 'duration_months']\n"
     ]
    }
   ],
   "source": [
    "print(numerical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything looks good; let us proceed with training. We need to specify **predictive** and **response** variables for each of the training and test sets. We set these by filtering the baseline and sample sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_baseline[predictive_features]\n",
    "X_test = df_sample[predictive_features]\n",
    "\n",
    "y_train = df_baseline[\"label\"]\n",
    "y_test = df_sample[\"label\"]\n",
    "\n",
    "X_train.to_json(\"X_train.json\", orient=\"records\", lines=True)\n",
    "X_test.to_json(\"X_test.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may now fit the classifier to the training data. Since \"it is worse to classify a customer as good when they are bad, than it is to classify a customer as bad when they are good\", we will use an **F_beta metric**, with `beta=2`, to judge the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=RepeatedStratifiedKFold(n_repeats=3, n_splits=10, random_state=0),\n",
       "             estimator=Pipeline(steps=[(&#x27;onehotencoder&#x27;,\n",
       "                                        OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)),\n",
       "                                       (&#x27;logisticregression&#x27;,\n",
       "                                        LogisticRegression(max_iter=1000,\n",
       "                                                           random_state=0))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;logisticregression__C&#x27;: array([1.00000000e-04, 1.45634848e-04, 2.12095089e-04, 3.08884360e-04,...\n",
       "       7.54312006e+01, 1.09854114e+02, 1.59985872e+02, 2.32995181e+02,\n",
       "       3.39322177e+02, 4.94171336e+02, 7.19685673e+02, 1.04811313e+03,\n",
       "       1.52641797e+03, 2.22299648e+03, 3.23745754e+03, 4.71486636e+03,\n",
       "       6.86648845e+03, 1.00000000e+04]),\n",
       "                         &#x27;logisticregression__class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
       "                         &#x27;logisticregression__solver&#x27;: [&#x27;liblinear&#x27;, &#x27;lbfgs&#x27;,\n",
       "                                                        &#x27;newton-cg&#x27;]},\n",
       "             scoring=make_scorer(fbeta_score, beta=2))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=RepeatedStratifiedKFold(n_repeats=3, n_splits=10, random_state=0),\n",
       "             estimator=Pipeline(steps=[(&#x27;onehotencoder&#x27;,\n",
       "                                        OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)),\n",
       "                                       (&#x27;logisticregression&#x27;,\n",
       "                                        LogisticRegression(max_iter=1000,\n",
       "                                                           random_state=0))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;logisticregression__C&#x27;: array([1.00000000e-04, 1.45634848e-04, 2.12095089e-04, 3.08884360e-04,...\n",
       "       7.54312006e+01, 1.09854114e+02, 1.59985872e+02, 2.32995181e+02,\n",
       "       3.39322177e+02, 4.94171336e+02, 7.19685673e+02, 1.04811313e+03,\n",
       "       1.52641797e+03, 2.22299648e+03, 3.23745754e+03, 4.71486636e+03,\n",
       "       6.86648845e+03, 1.00000000e+04]),\n",
       "                         &#x27;logisticregression__class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
       "                         &#x27;logisticregression__solver&#x27;: [&#x27;liblinear&#x27;, &#x27;lbfgs&#x27;,\n",
       "                                                        &#x27;newton-cg&#x27;]},\n",
       "             scoring=make_scorer(fbeta_score, beta=2))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;onehotencoder&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)),\n",
       "                (&#x27;logisticregression&#x27;,\n",
       "                 LogisticRegression(max_iter=1000, random_state=0))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=0)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=RepeatedStratifiedKFold(n_repeats=3, n_splits=10, random_state=0),\n",
       "             estimator=Pipeline(steps=[('onehotencoder',\n",
       "                                        OneHotEncoder(handle_unknown='ignore')),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression(max_iter=1000,\n",
       "                                                           random_state=0))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'logisticregression__C': array([1.00000000e-04, 1.45634848e-04, 2.12095089e-04, 3.08884360e-04,...\n",
       "       7.54312006e+01, 1.09854114e+02, 1.59985872e+02, 2.32995181e+02,\n",
       "       3.39322177e+02, 4.94171336e+02, 7.19685673e+02, 1.04811313e+03,\n",
       "       1.52641797e+03, 2.22299648e+03, 3.23745754e+03, 4.71486636e+03,\n",
       "       6.86648845e+03, 1.00000000e+04]),\n",
       "                         'logisticregression__class_weight': ['balanced', None],\n",
       "                         'logisticregression__solver': ['liblinear', 'lbfgs',\n",
       "                                                        'newton-cg']},\n",
       "             scoring=make_scorer(fbeta_score, beta=2))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will take a few minutes to complete\n",
    "clf_GS = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=parameters,\n",
    "    n_jobs=-1,\n",
    "    scoring=make_scorer(fbeta_score, beta=2),\n",
    "    cv=RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=0),\n",
    ")\n",
    "clf_GS.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;onehotencoder&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)),\n",
       "                (&#x27;logisticregression&#x27;,\n",
       "                 LogisticRegression(C=0.00021209508879201905,\n",
       "                                    class_weight=&#x27;balanced&#x27;, max_iter=1000,\n",
       "                                    random_state=0, solver=&#x27;newton-cg&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;onehotencoder&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)),\n",
       "                (&#x27;logisticregression&#x27;,\n",
       "                 LogisticRegression(C=0.00021209508879201905,\n",
       "                                    class_weight=&#x27;balanced&#x27;, max_iter=1000,\n",
       "                                    random_state=0, solver=&#x27;newton-cg&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.00021209508879201905, class_weight=&#x27;balanced&#x27;,\n",
       "                   max_iter=1000, random_state=0, solver=&#x27;newton-cg&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('onehotencoder', OneHotEncoder(handle_unknown='ignore')),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=0.00021209508879201905,\n",
       "                                    class_weight='balanced', max_iter=1000,\n",
       "                                    random_state=0, solver='newton-cg'))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_GS.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the parameters of the best estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__C': 0.00021209508879201905,\n",
       " 'logisticregression__class_weight': 'balanced',\n",
       " 'logisticregression__solver': 'newton-cg'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_GS.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the best logistic regression classifier is one with a `solver='lbfgs'` and `class_weight='balanced'`. This classifier achived the best score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6745196012183637"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_GS.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**II - Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before saving our trained model for further use, let's look at some performance metrics. We will evaluate the model on both the training and test sets; we would like to see a stable performance.\n",
    "\n",
    "For repeatability, let's define a function which computes multiple metrics at-a-time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_classification_metrics(\n",
    "    y_true: pandas.Series, y_preds: pandas.Series\n",
    ") -> List:\n",
    "    \"\"\"\n",
    "    A function to evaluate a binary classification model, given true and predicted labels.\n",
    "\n",
    "    Args:\n",
    "        y_true (pd.Series): true (actual) labels\n",
    "        y_preds (pd.Series): predicted labels (as scored by model)\n",
    "\n",
    "    Returns:\n",
    "        (List): Classification performance metrics: accuracy, balanced accuracy, precision, recall, f1, f2\n",
    "    \"\"\"\n",
    "\n",
    "    return [\n",
    "        accuracy_score(y_true, y_preds),\n",
    "        balanced_accuracy_score(y_true, y_preds),\n",
    "        precision_score(y_true, y_preds),\n",
    "        recall_score(y_true, y_preds),\n",
    "        f1_score(y_true, y_preds),\n",
    "        fbeta_score(y_true, y_preds, beta=2),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now compute predictions on both training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds = clf_GS.best_estimator_.predict(X_test)\n",
    "y_train_preds = clf_GS.best_estimator_.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us quickly verify that the model is not trivial, i.e., predicting the default (dominant) class (label=0) for all records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Label Distribution: \n",
      " 0    107\n",
      "1     93\n",
      "dtype: int64\n",
      "\n",
      "Train Label Distribution: \n",
      " 0    451\n",
      "1    349\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Test  Label Distribution: \\n\", pandas.Series(y_test_preds).value_counts())\n",
    "print(\"\\nTrain Label Distribution: \\n\", pandas.Series(y_train_preds).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will display performance metrics in a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preformance_df = pandas.DataFrame(\n",
    "    data=[{}],\n",
    "    columns=[\n",
    "        \"Accuracy\",\n",
    "        \"Balanced Accuracy\",\n",
    "        \"Precision\",\n",
    "        \"Recall\",\n",
    "        \"F1 score\",\n",
    "        \"F2 Score\",\n",
    "    ],\n",
    "    index=[\"Training Set\", \"Test Set\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "preformance_df.loc[\"Training Set\", :] = binary_classification_metrics(\n",
    "    y_true=y_train, y_preds=y_train_preds\n",
    ")\n",
    "preformance_df.loc[\"Test Set\", :] = binary_classification_metrics(\n",
    "    y_true=y_test, y_preds=y_test_preds\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how our model performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>F2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training Set</th>\n",
       "      <td>0.724</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Set</th>\n",
       "      <td>0.665</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Accuracy  Balanced Accuracy  Precision  Recall  F1 score  \\\n",
       "Training Set     0.724              0.735      0.530   0.764     0.626   \n",
       "Test Set         0.665              0.682      0.452   0.724     0.556   \n",
       "\n",
       "              F2 Score  \n",
       "Training Set     0.702  \n",
       "Test Set         0.646  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preformance_df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Observations:\n",
    "1. For many metrics, the performance on the training set is not too far off from the performance on the test set; for others, performance degraded on new data, inidicating either and over-fit model, or simply a bad split of train/test. Keep in mind that the overall dataset is small, comprising of 800 training samples and 200 test samples.\n",
    "2. Further model improvements are needed to achieve better F2 scores. Generally, a binary classifier is considered \"good\" for F_beta scores > 0.7. \n",
    "3. The fact that balanced accuracy and accuracy are close is a good indication that the model is not trivial. Balanced accuracy takes into account the imbalance of the label. Recall that the best estimator found by GridSearch was achieved for 'logisticregression__class_weight': 'balanced'.\n",
    "4. The model, as it stands, achieves almost the same accuracy as the trivial model (around 70%). One must keep in mind, however, that the trivial model fails on all other metrics, since it assigns the same default value for all samples.\n",
    "\n",
    "For now, we will contend with this model and use it to produce new predictions. A logistic regressin , when applicable, is often a good champion model, to be challenged later by other modeling techniques, such as Neural Networks, Decision Trees, SVMs, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**III - Saving and Loading the Trained Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is **trained** and **evaluated**, we save it in a binary format. It will then be loaded and used to make new predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf_GS.best_estimator_, open(\"logreg_classifier.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is reloaded on-demand as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_classifier = pickle.load(open(\"logreg_classifier.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions are produced on-demand by calling the `predict()` function on a dataframe of input samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_preds = logreg_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    107\n",
       "1     93\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.Series(new_preds).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IV - Evaluating Bias on Protected Classes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `gender` and `age_years` are protected classes, we have excluded them from the list of predictive features. However, this does not guarantee that the model is not implicitly biased, as `gender` and/or `age_years` could potentially be inferred from other features. It is therefore imperative that we evaluate our model for Ethical Bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To that end, let us produce some predictions and append them to our labeled baseline and sample sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline_scored = df_baseline.copy(deep=True)\n",
    "df_baseline_scored[\"score\"] = logreg_classifier.predict(\n",
    "    df_baseline[predictive_features]\n",
    ")\n",
    "\n",
    "df_sample_scored = df_sample.copy(deep=True)\n",
    "df_sample_scored[\"score\"] = logreg_classifier.predict(df_sample[predictive_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `Aequitas` library to compute bias metrics. The library requires the true label to be encoded as 'label_value', so let us rename that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline_scored.rename(columns={\"label\": \"label_value\"}, inplace=True)\n",
    "df_sample_scored.rename(columns={\"label\": \"label_value\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, protected classes must be of a catgeorical type, so that bias metrics are computed for each discrete group. To that end, we ill map `age_years` to an `age_over_forty` boolean column, since 40 is the legal cutoff for ageism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline_scored[\"age_over_forty\"] = (df_baseline_scored[\"age_years\"] > 40).astype(\n",
    "    str\n",
    ")\n",
    "df_sample_scored[\"age_over_forty\"] = (df_sample_scored[\"age_years\"] > 40).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save these two DataFrames before proceeding further:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline_scored.to_json(\"df_baseline_scored.json\", orient=\"records\", lines=True)\n",
    "df_sample_scored.to_json(\"df_sample_scored.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we call the aequitas preprocessing function on our datasets, filtered to the features we care about: `score` (prediction), `label_value` (true label), `age_over_forty` and `gender` (protected classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline_scored_processed, _ = preprocess_input_df(\n",
    "    df_baseline_scored.loc[:, [\"score\", \"label_value\", \"gender\", \"age_over_forty\"]]\n",
    ")\n",
    "df_sample_scored_processed, _ = preprocess_input_df(\n",
    "    df_sample_scored.loc[:, [\"score\", \"label_value\", \"gender\", \"age_over_forty\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by computing some `Group` Metrics. These are raw (count) metrics which display the representation of different groups in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/semerhi/.pyenv/versions/3.8.3/envs/german_credit_383_env/lib/python3.8/site-packages/aequitas/group.py:182: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, 'score'] = df.loc[:,'score'].astype(float)\n",
      "/home/semerhi/.pyenv/versions/3.8.3/envs/german_credit_383_env/lib/python3.8/site-packages/aequitas/group.py:182: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, 'score'] = df.loc[:,'score'].astype(float)\n"
     ]
    }
   ],
   "source": [
    "xtab_baseline, _ = Group().get_crosstabs(df_baseline_scored_processed)\n",
    "xtab_sample, _ = Group().get_crosstabs(df_sample_scored_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_metrics_baseline = Group().list_absolute_metrics(xtab_baseline)\n",
    "absolute_metrics_sample = Group().list_absolute_metrics(xtab_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the absolute metrics, computed on baseline and sample sets, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute_name</th>\n",
       "      <th>attribute_value</th>\n",
       "      <th>tpr</th>\n",
       "      <th>tnr</th>\n",
       "      <th>for</th>\n",
       "      <th>fdr</th>\n",
       "      <th>fpr</th>\n",
       "      <th>fnr</th>\n",
       "      <th>npv</th>\n",
       "      <th>precision</th>\n",
       "      <th>ppr</th>\n",
       "      <th>pprev</th>\n",
       "      <th>prev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gender</td>\n",
       "      <td>female</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gender</td>\n",
       "      <td>male</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age_over_forty</td>\n",
       "      <td>False</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>age_over_forty</td>\n",
       "      <td>True</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   attribute_name attribute_value   tpr   tnr   for   fdr   fpr   fnr   npv  \\\n",
       "0          gender          female  0.80  0.67  0.14  0.43  0.33  0.20  0.86   \n",
       "1          gender            male  0.75  0.72  0.12  0.49  0.28  0.25  0.88   \n",
       "2  age_over_forty           False  0.76  0.69  0.14  0.47  0.31  0.24  0.86   \n",
       "3  age_over_forty            True  0.79  0.74  0.09  0.48  0.26  0.21  0.91   \n",
       "\n",
       "   precision   ppr  pprev  prev  \n",
       "0       0.57  0.34   0.50  0.35  \n",
       "1       0.51  0.66   0.41  0.28  \n",
       "2       0.53  0.74   0.45  0.32  \n",
       "3       0.52  0.26   0.40  0.27  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtab_baseline[[\"attribute_name\", \"attribute_value\"] + absolute_metrics_baseline].round(\n",
    "    2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute_name</th>\n",
       "      <th>attribute_value</th>\n",
       "      <th>tpr</th>\n",
       "      <th>tnr</th>\n",
       "      <th>for</th>\n",
       "      <th>fdr</th>\n",
       "      <th>fpr</th>\n",
       "      <th>fnr</th>\n",
       "      <th>npv</th>\n",
       "      <th>precision</th>\n",
       "      <th>ppr</th>\n",
       "      <th>pprev</th>\n",
       "      <th>prev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gender</td>\n",
       "      <td>female</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gender</td>\n",
       "      <td>male</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age_over_forty</td>\n",
       "      <td>False</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>age_over_forty</td>\n",
       "      <td>True</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   attribute_name attribute_value   tpr   tnr   for   fdr   fpr   fnr   npv  \\\n",
       "0          gender          female  0.68  0.70  0.20  0.45  0.30  0.32  0.80   \n",
       "1          gender            male  0.76  0.61  0.12  0.60  0.39  0.24  0.88   \n",
       "2  age_over_forty           False  0.72  0.58  0.17  0.57  0.42  0.28  0.83   \n",
       "3  age_over_forty            True  0.73  0.82  0.10  0.43  0.18  0.27  0.90   \n",
       "\n",
       "   precision   ppr  pprev  prev  \n",
       "0       0.55  0.33   0.43  0.35  \n",
       "1       0.40  0.67   0.48  0.26  \n",
       "2       0.43  0.85   0.51  0.30  \n",
       "3       0.57  0.15   0.31  0.24  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtab_sample[[\"attribute_name\", \"attribute_value\"] + absolute_metrics_sample].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A complete description of the metrics above can be found here: https://github.com/dssg/aequitas#aequitas-group-metrics\n",
    "\n",
    "Generally, one would want a model that achieves similar metrics across different protected groups. One of the areas of concern for our model is the fact that `ppr`, `predicted positive rate` , varies wildly between groups. The imbalance of the grous in the data could be the cause."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add some raw counts (group sizes) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>score_threshold</th>\n",
       "      <th>k</th>\n",
       "      <th>attribute_name</th>\n",
       "      <th>attribute_value</th>\n",
       "      <th>pp</th>\n",
       "      <th>pn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "      <th>tp</th>\n",
       "      <th>group_label_pos</th>\n",
       "      <th>group_label_neg</th>\n",
       "      <th>group_size</th>\n",
       "      <th>total_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>binary 0/1</td>\n",
       "      <td>349</td>\n",
       "      <td>gender</td>\n",
       "      <td>female</td>\n",
       "      <td>118</td>\n",
       "      <td>120</td>\n",
       "      <td>51</td>\n",
       "      <td>17</td>\n",
       "      <td>103</td>\n",
       "      <td>67</td>\n",
       "      <td>84</td>\n",
       "      <td>154</td>\n",
       "      <td>238</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>binary 0/1</td>\n",
       "      <td>349</td>\n",
       "      <td>gender</td>\n",
       "      <td>male</td>\n",
       "      <td>231</td>\n",
       "      <td>331</td>\n",
       "      <td>113</td>\n",
       "      <td>40</td>\n",
       "      <td>291</td>\n",
       "      <td>118</td>\n",
       "      <td>158</td>\n",
       "      <td>404</td>\n",
       "      <td>562</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>binary 0/1</td>\n",
       "      <td>349</td>\n",
       "      <td>age_over_forty</td>\n",
       "      <td>False</td>\n",
       "      <td>257</td>\n",
       "      <td>314</td>\n",
       "      <td>120</td>\n",
       "      <td>44</td>\n",
       "      <td>270</td>\n",
       "      <td>137</td>\n",
       "      <td>181</td>\n",
       "      <td>390</td>\n",
       "      <td>571</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>binary 0/1</td>\n",
       "      <td>349</td>\n",
       "      <td>age_over_forty</td>\n",
       "      <td>True</td>\n",
       "      <td>92</td>\n",
       "      <td>137</td>\n",
       "      <td>44</td>\n",
       "      <td>13</td>\n",
       "      <td>124</td>\n",
       "      <td>48</td>\n",
       "      <td>61</td>\n",
       "      <td>168</td>\n",
       "      <td>229</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_id score_threshold    k  attribute_name attribute_value   pp   pn  \\\n",
       "0         0      binary 0/1  349          gender          female  118  120   \n",
       "1         0      binary 0/1  349          gender            male  231  331   \n",
       "2         0      binary 0/1  349  age_over_forty           False  257  314   \n",
       "3         0      binary 0/1  349  age_over_forty            True   92  137   \n",
       "\n",
       "    fp  fn   tn   tp  group_label_pos  group_label_neg  group_size  \\\n",
       "0   51  17  103   67               84              154         238   \n",
       "1  113  40  291  118              158              404         562   \n",
       "2  120  44  270  137              181              390         571   \n",
       "3   44  13  124   48               61              168         229   \n",
       "\n",
       "   total_entities  \n",
       "0             800  \n",
       "1             800  \n",
       "2             800  \n",
       "3             800  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtab_baseline[\n",
    "    [col for col in xtab_baseline.columns if col not in absolute_metrics_baseline]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>score_threshold</th>\n",
       "      <th>k</th>\n",
       "      <th>attribute_name</th>\n",
       "      <th>attribute_value</th>\n",
       "      <th>pp</th>\n",
       "      <th>pn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "      <th>tp</th>\n",
       "      <th>group_label_pos</th>\n",
       "      <th>group_label_neg</th>\n",
       "      <th>group_size</th>\n",
       "      <th>total_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>binary 0/1</td>\n",
       "      <td>93</td>\n",
       "      <td>gender</td>\n",
       "      <td>female</td>\n",
       "      <td>31</td>\n",
       "      <td>41</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>47</td>\n",
       "      <td>72</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>binary 0/1</td>\n",
       "      <td>93</td>\n",
       "      <td>gender</td>\n",
       "      <td>male</td>\n",
       "      <td>62</td>\n",
       "      <td>66</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>58</td>\n",
       "      <td>25</td>\n",
       "      <td>33</td>\n",
       "      <td>95</td>\n",
       "      <td>128</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>binary 0/1</td>\n",
       "      <td>93</td>\n",
       "      <td>age_over_forty</td>\n",
       "      <td>False</td>\n",
       "      <td>79</td>\n",
       "      <td>76</td>\n",
       "      <td>45</td>\n",
       "      <td>13</td>\n",
       "      <td>63</td>\n",
       "      <td>34</td>\n",
       "      <td>47</td>\n",
       "      <td>108</td>\n",
       "      <td>155</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>binary 0/1</td>\n",
       "      <td>93</td>\n",
       "      <td>age_over_forty</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_id score_threshold   k  attribute_name attribute_value  pp  pn  fp  \\\n",
       "0         0      binary 0/1  93          gender          female  31  41  14   \n",
       "1         0      binary 0/1  93          gender            male  62  66  37   \n",
       "2         0      binary 0/1  93  age_over_forty           False  79  76  45   \n",
       "3         0      binary 0/1  93  age_over_forty            True  14  31   6   \n",
       "\n",
       "   fn  tn  tp  group_label_pos  group_label_neg  group_size  total_entities  \n",
       "0   8  33  17               25               47          72             200  \n",
       "1   8  58  25               33               95         128             200  \n",
       "2  13  63  34               47              108         155             200  \n",
       "3   3  28   8               11               34          45             200  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtab_sample[[col for col in xtab_sample.columns if col not in absolute_metrics_sample]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have computed `Group` metrics, we can move on to `Bias` metrics. Bias is computed as the ratio of group metrics. This requires defining a reference group for each protected class. In the case of gender, we choose reference_group='male'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_disparity_predefined_group()\n",
      "get_disparity_predefined_group()\n"
     ]
    }
   ],
   "source": [
    "bdf_baseline = Bias().get_disparity_predefined_groups(\n",
    "    xtab_baseline,\n",
    "    original_df=df_baseline_scored_processed,\n",
    "    ref_groups_dict={\"gender\": \"male\", \"age_over_forty\": \"False\"},\n",
    "    alpha=0.05,\n",
    "    mask_significance=True,\n",
    ")\n",
    "\n",
    "bdf_sample = Bias().get_disparity_predefined_groups(\n",
    "    xtab_sample,\n",
    "    original_df=df_sample_scored_processed,\n",
    "    ref_groups_dict={\"gender\": \"male\", \"age_over_forty\": \"False\"},\n",
    "    alpha=0.05,\n",
    "    mask_significance=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute **disparity** metrics as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_disparities_baseline = Bias().list_disparities(bdf_baseline)\n",
    "calculated_disparities_sample = Bias().list_disparities(bdf_sample)\n",
    "\n",
    "disparity_metrics_df_baseline = bdf_baseline[\n",
    "    [\"attribute_name\", \"attribute_value\"] + calculated_disparities_baseline\n",
    "]\n",
    "disparity_metrics_df_sample = bdf_sample[\n",
    "    [\"attribute_name\", \"attribute_value\"] + calculated_disparities_sample\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the computed disparity metrics on baseline and sample sets, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute_name</th>\n",
       "      <th>attribute_value</th>\n",
       "      <th>ppr_disparity</th>\n",
       "      <th>pprev_disparity</th>\n",
       "      <th>precision_disparity</th>\n",
       "      <th>fdr_disparity</th>\n",
       "      <th>for_disparity</th>\n",
       "      <th>fpr_disparity</th>\n",
       "      <th>fnr_disparity</th>\n",
       "      <th>tpr_disparity</th>\n",
       "      <th>tnr_disparity</th>\n",
       "      <th>npv_disparity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gender</td>\n",
       "      <td>female</td>\n",
       "      <td>0.511</td>\n",
       "      <td>1.206</td>\n",
       "      <td>1.112</td>\n",
       "      <td>0.884</td>\n",
       "      <td>1.172</td>\n",
       "      <td>1.184</td>\n",
       "      <td>0.799</td>\n",
       "      <td>1.068</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gender</td>\n",
       "      <td>male</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age_over_forty</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>age_over_forty</td>\n",
       "      <td>True</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.979</td>\n",
       "      <td>1.024</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.877</td>\n",
       "      <td>1.040</td>\n",
       "      <td>1.066</td>\n",
       "      <td>1.053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   attribute_name attribute_value  ppr_disparity  pprev_disparity  \\\n",
       "0          gender          female          0.511            1.206   \n",
       "1          gender            male          1.000            1.000   \n",
       "2  age_over_forty           False          1.000            1.000   \n",
       "3  age_over_forty            True          0.358            0.893   \n",
       "\n",
       "   precision_disparity  fdr_disparity  for_disparity  fpr_disparity  \\\n",
       "0                1.112          0.884          1.172          1.184   \n",
       "1                1.000          1.000          1.000          1.000   \n",
       "2                1.000          1.000          1.000          1.000   \n",
       "3                0.979          1.024          0.677          0.851   \n",
       "\n",
       "   fnr_disparity  tpr_disparity  tnr_disparity  npv_disparity  \n",
       "0          0.799          1.068          0.929          0.976  \n",
       "1          1.000          1.000          1.000          1.000  \n",
       "2          1.000          1.000          1.000          1.000  \n",
       "3          0.877          1.040          1.066          1.053  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disparity_metrics_df_baseline.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute_name</th>\n",
       "      <th>attribute_value</th>\n",
       "      <th>ppr_disparity</th>\n",
       "      <th>pprev_disparity</th>\n",
       "      <th>precision_disparity</th>\n",
       "      <th>fdr_disparity</th>\n",
       "      <th>for_disparity</th>\n",
       "      <th>fpr_disparity</th>\n",
       "      <th>fnr_disparity</th>\n",
       "      <th>tpr_disparity</th>\n",
       "      <th>tnr_disparity</th>\n",
       "      <th>npv_disparity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gender</td>\n",
       "      <td>female</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.889</td>\n",
       "      <td>1.360</td>\n",
       "      <td>0.757</td>\n",
       "      <td>1.610</td>\n",
       "      <td>0.765</td>\n",
       "      <td>1.320</td>\n",
       "      <td>0.898</td>\n",
       "      <td>1.150</td>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gender</td>\n",
       "      <td>male</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age_over_forty</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>age_over_forty</td>\n",
       "      <td>True</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.610</td>\n",
       "      <td>1.328</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.986</td>\n",
       "      <td>1.005</td>\n",
       "      <td>1.412</td>\n",
       "      <td>1.090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   attribute_name attribute_value  ppr_disparity  pprev_disparity  \\\n",
       "0          gender          female          0.500            0.889   \n",
       "1          gender            male          1.000            1.000   \n",
       "2  age_over_forty           False          1.000            1.000   \n",
       "3  age_over_forty            True          0.177            0.610   \n",
       "\n",
       "   precision_disparity  fdr_disparity  for_disparity  fpr_disparity  \\\n",
       "0                1.360          0.757          1.610          0.765   \n",
       "1                1.000          1.000          1.000          1.000   \n",
       "2                1.000          1.000          1.000          1.000   \n",
       "3                1.328          0.752          0.566          0.424   \n",
       "\n",
       "   fnr_disparity  tpr_disparity  tnr_disparity  npv_disparity  \n",
       "0          1.320          0.898          1.150          0.916  \n",
       "1          1.000          1.000          1.000          1.000  \n",
       "2          1.000          1.000          1.000          1.000  \n",
       "3          0.986          1.005          1.412          1.090  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disparity_metrics_df_sample.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the disparity metrics above are worrisome! A good rule of thumb is for bias metrics to be within 20% of the reference group. Thus, values outside of (0.8,1.25) are cause for concern. We might need to retrain the model, possibly with better feature engineering. That's an exercise for a later time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**V - Preparing Model Code for Deployment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing for deployment is best-demonstrated through and example. Let's look at the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'List' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 68\u001b[0m\n\u001b[1;32m     63\u001b[0m     data[\u001b[39m\"\u001b[39m\u001b[39mpredicted_score\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m logreg_classifier\u001b[39m.\u001b[39mpredict(data[predictive_features])\n\u001b[1;32m     65\u001b[0m     \u001b[39mreturn\u001b[39;00m data\u001b[39m.\u001b[39mto_dict(orient\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrecords\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m---> 68\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmetrics\u001b[39m(data: pandas\u001b[39m.\u001b[39mDataFrame) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mdict\u001b[39m]:\n\u001b[1;32m     69\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[39m    A function to compute Group and Bias metrics on scored and labeled data, containing protected classes.\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39m        (List[dict]): Group and Bias metrics for each protected class.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     \u001b[39m# To measure Bias towards gender, filter DataFrame to \"score\", \"label_value\" (ground truth), and\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     \u001b[39m# \"gender\" (protected attribute)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'List' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import pickle\n",
    "\n",
    "from aequitas.preprocessing import preprocess_input_df\n",
    "from aequitas.group import Group\n",
    "from aequitas.bias import Bias\n",
    "\n",
    "\n",
    "def init() -> None:\n",
    "    \"\"\"\n",
    "    A function to load the trained model artifact (.pickle) as a glocal variable.\n",
    "    The model will be used by other functions to produce predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    global logreg_classifier\n",
    "\n",
    "    # load pickled logistic regression model\n",
    "    logreg_classifier = pickle.load(open(\"logreg_classifier.pickle\", \"rb\"))\n",
    "\n",
    "\n",
    "def score(data: dict) -> dict:\n",
    "    \"\"\"\n",
    "    A function to predict loan default/pay-off, given a loan application sample (record).\n",
    "\n",
    "    Args:\n",
    "        data (dict): input dictionary to be scored, containing predictive features.\n",
    "\n",
    "    Returns:\n",
    "        (dict): Scored (predicted) input data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Turn input data into a 1-record DataFrame\n",
    "    data = pandas.DataFrame([data])\n",
    "\n",
    "    # There are only two unique values in data.number_people_liable.\n",
    "    # Treat it as a categorical feature, to mimic training process\n",
    "    data.number_people_liable = data.number_people_liable.astype(\"category\")\n",
    "\n",
    "    # Alternitavely, these features can be saved (pickled) and re-loaded\n",
    "    predictive_features = [\n",
    "        \"installment_plans\",\n",
    "        \"job\",\n",
    "        \"number_people_liable\",\n",
    "        \"savings_account\",\n",
    "        \"debtors_guarantors\",\n",
    "        \"housing\",\n",
    "        \"credit_amount\",\n",
    "        \"installment_rate\",\n",
    "        \"credit_history\",\n",
    "        \"foreign_worker\",\n",
    "        \"number_existing_credits\",\n",
    "        \"purpose\",\n",
    "        \"telephone\",\n",
    "        \"present_residence_since\",\n",
    "        \"checking_status\",\n",
    "        \"duration_months\",\n",
    "        \"present_employment_since\",\n",
    "        \"property\",\n",
    "    ]\n",
    "\n",
    "    # Predict using saved model\n",
    "    data[\"predicted_score\"] = logreg_classifier.predict(data[predictive_features])\n",
    "\n",
    "    return data.to_dict(orient=\"records\")[0]\n",
    "\n",
    "\n",
    "def metrics(data: pandas.DataFrame) -> List[dict]:\n",
    "    \"\"\"\n",
    "    A function to compute Group and Bias metrics on scored and labeled data, containing protected classes.\n",
    "\n",
    "    Args:\n",
    "        data (pandas.DataFrame): Dataframe of loan applications, including ground truths, predictions.\n",
    "\n",
    "    Returns:\n",
    "        (List[dict]): Group and Bias metrics for each protected class.\n",
    "    \"\"\"\n",
    "\n",
    "    # To measure Bias towards gender, filter DataFrame to \"score\", \"label_value\" (ground truth), and\n",
    "    # \"gender\" (protected attribute)\n",
    "    data_scored = data[[\"score\", \"label_value\", \"gender\", \"age_over_forty\"]]\n",
    "\n",
    "    # Process DataFrame\n",
    "    data_scored_processed, _ = preprocess_input_df(data_scored)\n",
    "\n",
    "    # Group Metrics\n",
    "    xtab, _ = Group().get_crosstabs(data_scored_processed)\n",
    "\n",
    "    # Absolute metrics, such as 'tpr', 'tnr','precision', etc.\n",
    "    absolute_metrics = Group().list_absolute_metrics(xtab)\n",
    "\n",
    "    # DataFrame of calculated absolute metrics for each sample population group\n",
    "    absolute_metrics_df = xtab[\n",
    "        [\"attribute_name\", \"attribute_value\"] + absolute_metrics\n",
    "    ].round(2)\n",
    "\n",
    "    # For example:\n",
    "    \"\"\"\n",
    "        attribute_name  attribute_value     tpr     tnr  ... precision\n",
    "    0   gender          female              0.60    0.88 ... 0.75\n",
    "    1   gender          male                0.49    0.90 ... 0.64\n",
    "    2   age_over_forty  True                0.54    0.45 ... 0.23\n",
    "    3   age_over_forty  False               0.45    0.54 ... 0.32\n",
    "    \"\"\"\n",
    "\n",
    "    # Bias Metrics\n",
    "    # Disparities calculated in relation gender for \"male\" and \"female\"\n",
    "    bias_df = Bias().get_disparity_predefined_groups(\n",
    "        xtab,\n",
    "        original_df=data_scored_processed,\n",
    "        ref_groups_dict={\"gender\": \"male\", \"age_over_forty\": \"False\"},\n",
    "        alpha=0.05,\n",
    "        mask_significance=True,\n",
    "    )\n",
    "\n",
    "    # Disparity metrics added to bias DataFrame\n",
    "    calculated_disparities = Bias().list_disparities(bias_df)\n",
    "\n",
    "    disparity_metrics_df = bias_df[\n",
    "        [\"attribute_name\", \"attribute_value\"] + calculated_disparities\n",
    "    ].round(3)\n",
    "\n",
    "    # For example:\n",
    "    \"\"\"\n",
    "        attribute_name\tattribute_value    ppr_disparity   precision_disparity\n",
    "    0   gender          female             0.714            1.417\n",
    "    1   gender          male               1.000            1.000\n",
    "    2   age_over_forty  True                0.54            1.234\n",
    "    3   age_over_forty  False              1.000            1.000\n",
    "    \"\"\"\n",
    "\n",
    "    # Output a JSON object of calculated metrics\n",
    "    return {\n",
    "        \"group_metrics\": absolute_metrics_df.to_dict(orient=\"records\"),\n",
    "        \"bias_metrics\": disparity_metrics_df.to_dict(orient=\"records\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four main sections to this model:\n",
    "1. Library imports\n",
    "2. `init` function\n",
    "3. `score` function\n",
    "4. `metrics` function\n",
    "\n",
    "**Library** imports are always at the top. We don't need to include all libraries that we used for training and model evaluation. We just need the libraries for processing and scoring.\n",
    "\n",
    "The **`init`** function runs once per deployment, and is used to load and persist into memory any variable that needs to be accessed at scoring time. For example, the `init` function is where we load the saved model binary. We make the variable global so it can be accessed from the scoring function.\n",
    "\n",
    "The **`score`** function is the function that runs anytime we make a scoring (prediction) request. This is where we put our prediction code. We have to remember to include any steps that were not captured by the pipeline, such as feature engineering or re-encoding.\n",
    "\n",
    "The **`metrics`** functions is where model evaluation is carried out. In our example, this is the place where we replicate the calculations of Group and/or Bias metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us test our source code to see if we missed anything. We will load input data and scored input data to test both the scoring and metrics functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_sample = pandas.read_json(\"df_baseline.json\", lines=True, orient=\"records\")\n",
    "metrics_sample = pandas.read_json(\n",
    "    \"df_baseline_scored.json\", lines=True, orient=\"records\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the **`init`** function can load the trained model binary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No errors from the **`init`** function. Let us now call the **`score`** function on input data (first sample):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = score(score_sample.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 687,\n",
       " 'duration_months': 36,\n",
       " 'credit_amount': 2862,\n",
       " 'installment_rate': 4,\n",
       " 'present_residence_since': 3,\n",
       " 'age_years': 30,\n",
       " 'number_existing_credits': 1,\n",
       " 'checking_status': 'A12',\n",
       " 'credit_history': 'A33',\n",
       " 'purpose': 'A40',\n",
       " 'savings_account': 'A62',\n",
       " 'present_employment_since': 'A75',\n",
       " 'debtors_guarantors': 'A101',\n",
       " 'property': 'A124',\n",
       " 'installment_plans': 'A143',\n",
       " 'housing': 'A153',\n",
       " 'job': 'A173',\n",
       " 'number_people_liable': 1,\n",
       " 'telephone': 'A191',\n",
       " 'foreign_worker': 'A201',\n",
       " 'gender': 'male',\n",
       " 'label': 0,\n",
       " 'predicted_score': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>duration_months</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>installment_rate</th>\n",
       "      <th>present_residence_since</th>\n",
       "      <th>age_years</th>\n",
       "      <th>number_existing_credits</th>\n",
       "      <th>checking_status</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>...</th>\n",
       "      <th>property</th>\n",
       "      <th>installment_plans</th>\n",
       "      <th>housing</th>\n",
       "      <th>job</th>\n",
       "      <th>number_people_liable</th>\n",
       "      <th>telephone</th>\n",
       "      <th>foreign_worker</th>\n",
       "      <th>gender</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>687</td>\n",
       "      <td>36</td>\n",
       "      <td>2862</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>A12</td>\n",
       "      <td>A33</td>\n",
       "      <td>A40</td>\n",
       "      <td>...</td>\n",
       "      <td>A124</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  duration_months  credit_amount  installment_rate  \\\n",
       "0  687               36           2862                 4   \n",
       "\n",
       "   present_residence_since  age_years  number_existing_credits  \\\n",
       "0                        3         30                        1   \n",
       "\n",
       "  checking_status credit_history purpose  ... property installment_plans  \\\n",
       "0             A12            A33     A40  ...     A124              A143   \n",
       "\n",
       "  housing   job number_people_liable telephone foreign_worker  gender label  \\\n",
       "0    A153  A173                    1      A191           A201    male     0   \n",
       "\n",
       "  predicted_score  \n",
       "0               1  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame([scores])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have scores! Last but not least, let's call the **`metrics`** function on scored data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/semerhi/.pyenv/versions/3.8.3/envs/german_credit_383_env/lib/python3.8/site-packages/aequitas/group.py:182: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'score'] = df.loc[:,'score'].astype(float)\n",
      "/home/semerhi/.pyenv/versions/3.8.3/envs/german_credit_383_env/lib/python3.8/site-packages/aequitas/group.py:182: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, 'score'] = df.loc[:,'score'].astype(float)\n"
     ]
    }
   ],
   "source": [
    "bias = metrics(metrics_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute_name</th>\n",
       "      <th>attribute_value</th>\n",
       "      <th>tpr</th>\n",
       "      <th>tnr</th>\n",
       "      <th>for</th>\n",
       "      <th>fdr</th>\n",
       "      <th>fpr</th>\n",
       "      <th>fnr</th>\n",
       "      <th>npv</th>\n",
       "      <th>precision</th>\n",
       "      <th>ppr</th>\n",
       "      <th>pprev</th>\n",
       "      <th>prev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gender</td>\n",
       "      <td>female</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gender</td>\n",
       "      <td>male</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age_over_forty</td>\n",
       "      <td>False</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>age_over_forty</td>\n",
       "      <td>True</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   attribute_name attribute_value   tpr   tnr   for   fdr   fpr   fnr   npv  \\\n",
       "0          gender          female  0.80  0.67  0.14  0.43  0.33  0.20  0.86   \n",
       "1          gender            male  0.75  0.72  0.12  0.49  0.28  0.25  0.88   \n",
       "2  age_over_forty           False  0.76  0.69  0.14  0.47  0.31  0.24  0.86   \n",
       "3  age_over_forty            True  0.79  0.74  0.09  0.48  0.26  0.21  0.91   \n",
       "\n",
       "   precision   ppr  pprev  prev  \n",
       "0       0.57  0.34   0.50  0.35  \n",
       "1       0.51  0.66   0.41  0.28  \n",
       "2       0.53  0.74   0.45  0.32  \n",
       "3       0.52  0.26   0.40  0.27  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(bias[\"group_metrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute_name</th>\n",
       "      <th>attribute_value</th>\n",
       "      <th>ppr_disparity</th>\n",
       "      <th>pprev_disparity</th>\n",
       "      <th>precision_disparity</th>\n",
       "      <th>fdr_disparity</th>\n",
       "      <th>for_disparity</th>\n",
       "      <th>fpr_disparity</th>\n",
       "      <th>fnr_disparity</th>\n",
       "      <th>tpr_disparity</th>\n",
       "      <th>tnr_disparity</th>\n",
       "      <th>npv_disparity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gender</td>\n",
       "      <td>female</td>\n",
       "      <td>0.511</td>\n",
       "      <td>1.206</td>\n",
       "      <td>1.112</td>\n",
       "      <td>0.884</td>\n",
       "      <td>1.172</td>\n",
       "      <td>1.184</td>\n",
       "      <td>0.799</td>\n",
       "      <td>1.068</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gender</td>\n",
       "      <td>male</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age_over_forty</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>age_over_forty</td>\n",
       "      <td>True</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.979</td>\n",
       "      <td>1.024</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.877</td>\n",
       "      <td>1.040</td>\n",
       "      <td>1.066</td>\n",
       "      <td>1.053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   attribute_name attribute_value  ppr_disparity  pprev_disparity  \\\n",
       "0          gender          female          0.511            1.206   \n",
       "1          gender            male          1.000            1.000   \n",
       "2  age_over_forty           False          1.000            1.000   \n",
       "3  age_over_forty            True          0.358            0.893   \n",
       "\n",
       "   precision_disparity  fdr_disparity  for_disparity  fpr_disparity  \\\n",
       "0                1.112          0.884          1.172          1.184   \n",
       "1                1.000          1.000          1.000          1.000   \n",
       "2                1.000          1.000          1.000          1.000   \n",
       "3                0.979          1.024          0.677          0.851   \n",
       "\n",
       "   fnr_disparity  tpr_disparity  tnr_disparity  npv_disparity  \n",
       "0          0.799          1.068          0.929          0.976  \n",
       "1          1.000          1.000          1.000          1.000  \n",
       "2          1.000          1.000          1.000          1.000  \n",
       "3          0.877          1.040          1.066          1.053  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(bias[\"bias_metrics\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prefect!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('german_credit_383_env': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "6480478f1f596d979dd1ec9d1231d153604d8bc5cbb236e21e5a9bcf2b18aa20"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
